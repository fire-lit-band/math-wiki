实际上对于条件概率，我们直接看定义就是

（注，在概率论中，我们讲A$\cap$B写作AB，意思是AB同时发生的情况）

# 定义

The conditional probability of event $A$ given event $B$ occurs（在给定B发生的情况下问A的概率）, denoted by $P(A \mid B)$, is defined as
$P(A \mid B)=\frac{P(A \text { and } B)}{P(B)} \quad$ 
 $P(A), P(B)$ are called Marginal probability - probability of only 1 event occurring
P(A and B) is called Joint probability - probability of 2 or more events occurring together

## 两个极为重要的公式

### 全概率公式

The Law of Total Probability: Suppose $F_{1}, F_{2}, \ldots, F_{n} \quad$ are mutually exclusive events such that $\cup_{i=1}^{n} F_{i}=S$ Then, for any event $E, P(E)=\sum_{i=1}^{n} P\left(E \mid F_{i}\right) P\left(F_{i}\right)$
One-line proof:
$P(E)=P\left(\cup_{i}\left(E F_{i}\right)\right)=\sum_{i} P\left(E F_{i}\right)=\sum_{i} P\left(E \mid F_{i}\right) P\left(F_{i}\right)$

顾名思义，全概率公式，就是去看之前发生过什么，然后根据以前的因，去算现在的果

### 贝叶斯

Suppose $F_{1}, F_{2}, \ldots, F_{n}$ are mutually exclusive events such that $\cup_{i=1}^{n} F_{i}=S$. Then, for any event $E$,
$$
P\left(F_{j} \mid E\right)=\frac{P\left(E F_{j}\right)}{P(E)}=\frac{P\left(E \mid F_{j}\right) P\left(F_{j}\right)}{\sum_{i=1}^{n} P\left(E \mid F_{i}\right) P\left(F_{i}\right)}
$$
贝叶斯定理代表了由果溯因的想法（以后再补）

# 独立性

Two events, $A$ and $B$, are independent if the occurrence of event A does not affect the probability of occurrence of event $B$, or vice versa,then
 $P(A \mid B)=P(A)$, or$P(B \mid A)=P(B)$，or P(AB)=P(A)P(B)

定义特别简单，但是我这里要提一嘴

首先，上面的公式说明的是，如果A，B独立，是事件A发生与否对事件B发生的概率没有影响，反之亦然。

那么我们能不能用这个公式判断独立性呢？答案是不能。注意这边的用词”发生的概率“，换句话说，在这个公式成立的前提下，事件A的发生与否，不会对事件B的发生的概率的数字发生影响，但是否会对事件B的有影响呢，没说，

比如摇两个均匀的色子，记$A_i$是"点数和为i的倍数"，我们来看$A_2,A_3$当$A_2$没发生，$A_3$的可能值是{3,6,9,12}，但$A_2$发生了，$A_3$的可能值就变成了{6,12}的的确确发生了影响，但很明显，对于发生的概率，这个数字是没有影响的

换句话说，如果说我们计算出来这两个变量是独立的，并不能代表这两个变量独立的，能帮助我们判断这两个变量是否独立的，是否有关联的，是我们的知识，或者说常识

这个公式的用处在于，如果独立性等式是不成立的，那么这两个事件是不可能独立的，所以说我们通常将该公式用于独立性检验，而非判断独立性