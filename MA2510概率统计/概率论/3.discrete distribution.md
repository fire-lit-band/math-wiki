# random variable
A random variable (r.v.) is a real valued function whose
domain is the sample space S . Usually denoted by

Random variables are usually denoted by capital letters like X  
the number values that are assigned to the random variables are denoted by small letters x and y
# probablity distribution
就是每个点的概率是多少
离散的叫"probablity mass function"
$p(a)=P\{{X=a}\}=P(\{s \in S: X(s)=a\})$
continuous

# cumulative distribution function(cdf)
F(a)=P(X<=a)=$\sum_{\text {all } x \leq a} p(x)$
Relationship between pdf and cdf: The relationship between the pdf and cdf is expressed by
$$
\begin{gathered}
F(a)=P\{X \leq a\}=\int_{-\infty}^{a} f(x) d x \\
\frac{d}{d a} F(a)=f(a)
\end{gathered}
$$

 ## properties
 Properties of the Cumulative Distribution Function
All probability questions about $X$ can be answered in terms of the cdf $F$. For example,
$$
P(a<X \leq b)=F(b)-F(a) \text { for all } a<b
$$
F is non decreasing ,that is nondecreasing, that is, if $a<b$, then $F(a) \leq F(b)$.
2. $\lim _{b \rightarrow \infty} F(b)=1, \lim _{b \rightarrow-\infty} F(b)=0$
3. $F$ is right continuous. That is, for any $b$ and any decreasing sequence $\left\{b_{n}\right\}$ converging to $b$,
$\lim _{n \rightarrow \infty} F\left(b_{n}\right)=F(b)$

# variance
$$
\begin{aligned}
&\sigma^{2}=\operatorname{Var}[X] \\
&=E\left[(X-\mu)^{2}\right]=\sum(x-\mu)^{2} P(X=x) \\
&=E\left(X^{2}\right)-\mu^{2}=\sum x^{2} P(X=x)-\mu^{2}
\end{aligned}
$$
The standard deviation of a discrete random variable $X$ is
$$
\sigma=\sqrt{\operatorname{Var}[X]}
$$
var(ax+b)=a^2var(x)
# moiment
Definition: $n$-th moment of a random variable
The $n$-th moment of a random variable $X$ is defined by the expectation $E\left[X^{n}\right]$, where $n$ is a positive integer. In particular, the expectation $E[X]$ of $X$ is the first moment of $X$, and $E\left[X^{2}\right]$ is the second moment of $X$.
The $n$-th central moment (moment about the mean) of a random variable $X$ is defined by the expectation $E\left[(X-E[X])^{n}\right]$

# Binomial Experiment
Suppose that a trial (experiment) whose outcome can be classified as either a success or a failure. Let the random variable $X$ equal 1 when the outcome is a success and $X$ equal 0 when the outcome is a failure. Then the pmf of $X$ is determined by one parameter $p$ is
$$
\begin{aligned}
&p(1)=P(X=1)=p \\
&p(0)=P(X=0)=1-p
\end{aligned}
$$
$p(X=x)={ }_{n} C_{x} p^{x}(1-p)^{n-x}=\frac{n !}{x !(n-x) !} p^{x}(1-p)^{n-x} \quad x=0,1, \cdots, n$
expect:E(x)=np
varivance:np(1-p)
Bernoulli 就是n=1即可
shape of distribution:  p<0.5 , right‐skewed;p >0.5, left‐skewed
with n increase ，更加对称
我们认为np$\geq 5$且$nq\geq 5$（q=1-p)二项分布可以认为是正态分布
X~N(np,npq) ->X-np/sqrt(npq)~N(0,1) ->n\bar{p}-np/sqrt(npq)~N(0,1)上下同除以n,所以
$\hat{p} \sim N\left(p, \frac{p q}{n}\right) \Rightarrow Z=\frac{\hat{p}-p}{\sqrt{\frac{p q}{n}}} \sim N(0,1)$
# poisson random variable
 $p(i)=p\{X=i\}=e^{-\lambda} \frac{\lambda^{i}}{i !}, i=0,1,2, \ldots$
 E(x)=$\lambda$
 One use of the Poisson is to model the number of
“events” occurring in a certain period of time, e.
The number of claims to an insurer in a year.
number of times the price exceeds a certain value.
We call some event process a Poisson Process (with parameter $\lambda$ ) if the number of events occurring in any interval of length $t$ is a Poisson random variable with parameter $\lambda t$.
$$\begin{aligned}
&X: \text { Ho overs in the }[a, a+t] \\
&X \sim \operatorname{pois}(\lambda t)
\end{aligned}$$
当n≥20，p≤0.05可以认为二项分布是正态分布                                             
$\lambda=np$
![](Pasted%20image%2020220224005050.png)
# geometric random variable
Suppose that independent trials are performed, each having a probability $p, 0<p<1$, of being a success. Let $X$ be the number of trials required until the first success. The probability mass function of $X$ is
$$
P\{X=n\}=(1-p)^{n-1} p, n=1,2, \ldots
$$
E[x]=1/p,Var=(1-p)/p^2
# negative binomial distribution
$$P\{X=n\}=\left(\begin{array}{c}
n-1 \\
r-1
\end{array}\right) p^{r}(1-p)^{n-r}$$
E[X]=r/p,VAR(X)=r(1-p)/p^2
# hypergeometric random variance
$$P\{X=k\}=\frac{\left(\begin{array}{c}
K \\
k
\end{array}\right)\left(\begin{array}{l}
N-K \\
n-k
\end{array}\right)}{\left(\begin{array}{l}
N \\
n
\end{array}\right)}, \quad k=0,1,2, \ldots, n$$
We call some event process a Poisson Process (with parameter $\lambda$ ) if the number of events occurring in any interval of length $t$ is a Poisson random variable with parameter $\lambda t$.
$$
X: [a, a+t] \\
X \sim \operatorname{Pois}_{i}(\lambda t)
$$
